# Neuro-Biometrics â€” Improvement Roadmap

> Tá»•ng há»£p tá»« phÃ¢n tÃ­ch káº¿t quáº£ V1 vs V2 (commit `34c94bd`)
> Baseline: ResNet34+ArcFace â€” V1: 78.5-87.4% P@1, V2: 80.4-89.4% P@1, AUROC 0.42-0.56

---

## Phase 1: Statistical Validity & Quick Wins (1-2 ngÃ y)

### 1.1 TÄƒng seeds â‰¥ 5 ğŸ”´ CRITICAL
Nhiá»u improvement hiá»‡n táº¡i **náº±m trong khoáº£ng std** â†’ chÆ°a Ä‘á»§ statistical significance.
```bash
python experiments/v2_mamba/main.py --epochs 30 --seeds 5
python experiments/v1_baseline/main.py --epochs 30 --seeds 5
```
- ThÃªm bÃ¡o cÃ¡o **CI 95%** (confidence interval) bÃªn cáº¡nh mean Â± std
- Ká»³ vá»ng: KhÃ´ng tÄƒng accuracy nhÆ°ng **tÄƒng Ä‘á»™ tin cáº­y** cho má»i káº¿t luáº­n

### 1.2 ArcFace Hyperparameter Grid
Margin vÃ  scale máº·c Ä‘á»‹nh (m=0.3, s=30) chÆ°a optimal. Grid search nhá»:

| Param | Values | Notes |
|---|---|---|
| margin `m` | 0.2, **0.3**, 0.4, 0.5 | Cao hÆ¡n â†’ harder, discriminative hÆ¡n |
| scale `s` | 20, **30**, 40, 64 | Cao hÆ¡n â†’ sharper decision boundary |

- Cháº¡y riÃªng cho má»—i noise type (Gaussian/Powerline/EMG)
- Ká»³ vá»ng: **P@1 +2-3%**, nhanh nháº¥t trong táº¥t cáº£ improvements

### 1.3 Unit Test cho P@K Metrics
Fix P@5 (CMC@5 â†’ true Precision@5) Ä‘Ã£ lÃ m nhÆ°ng **chÆ°a cÃ³ test**.
- Viáº¿t unit test vá»›i synthetic data: 10 embeddings, known labels, verify P@1/P@5/CMC
- Äáº£m báº£o reproducibility giá»¯a cÃ¡c láº§n cháº¡y

---

## Phase 2: Loss & Training Strategy (3-5 ngÃ y)

### 2.1 Hybrid Loss: ArcFace + SupContrastive
ArcFace máº¡nh cho identification (P@1) nhÆ°ng yáº¿u cho verification (AUROC).
```python
loss = Î» * arcface_loss(emb, y) + (1 - Î») * supcon_loss(emb, y)
# Try Î» = {0.6, 0.7, 0.8}
```
- SupContrastive (pair-based) bá»• trá»£ tá»‘t hÆ¡n MultiSim (cÅ©ng proxy-based nhÆ° ArcFace)
- Ká»³ vá»ng: **AUROC +10-15%**, P@1 giá»¯ nguyÃªn hoáº·c tÄƒng nháº¹

### 2.2 Joint Fine-tune End-to-End
Hiá»‡n táº¡i 2-stage: denoiser denoise cho reconstruction, khÃ´ng cho identification.
```python
# After 2-stage training, unfreeze denoiser:
loss = Î± * si_snr_loss + Î² * arcface_loss
# LR 1e-5 to 3e-5, 5-10 epochs
```
- Denoiser sáº½ há»c denoise **theo hÆ°á»›ng tá»‘i Æ°u cho identification**
- Ká»³ vá»ng: **P@1 +3-5%**, **AUROC +5-10%**

### 2.3 Hard-Negative Mining
Thay random batch â†’ **subject-balanced sampler** + memory bank:
- Má»—i batch cÃ³ K subjects Ã— M samples/subject
- Memory bank lÆ°u embeddings gáº§n nháº¥t â†’ mine hardest negatives
- Ká»³ vá»ng: **AUROC +15-20%**, EER giáº£m Ä‘Ã¡ng ká»ƒ

---

## Phase 3: Data & Augmentation (3-5 ngÃ y)

### 3.1 Enhanced Augmentation
Hiá»‡n táº¡i chá»‰ cÃ³ noise jitter + amplitude scaling. ThÃªm:

| Augmentation | MÃ´ táº£ | Impact |
|---|---|---|
| **Time shift** | Dá»‹ch Â±50ms | Temporal invariance |
| **Channel dropout** | Zero random 1/4 channels | Robustness |
| **SpecAugment** | Mask frequency bands | Spectral robustness |
| **Mixup** | Blend 2 subjects (signal + label) | Regularization |
| **SNR curriculum** | Epoch 1-10: easy SNR â†’ Epoch 20-30: hard SNR | Progressive difficulty |

### 3.2 Cross-dataset Pre-training
Dataset hiá»‡n táº¡i nhá» (~14 subjects). Pre-train denoiser trÃªn:
- **PhysioNet EEG Motor Movement** (109 subjects)
- **BCI Competition IV** datasets
- Sau Ä‘Ã³ fine-tune embedder trÃªn target dataset
- Ká»³ vá»ng: **P@1 +5-10%** (more data = more generalizable features)

---

## Phase 4: Architecture (5-7 ngÃ y)

### 4.1 1D Embedder (thay 2D reshape)
Reshape (B,4,800) â†’ (B,4,25,32) lÃ  hacky. DÃ¹ng **1D ResNet** trá»±c tiáº¿p:
```python
# Current: EEG 1D â†’ reshape 2D â†’ ResNet2D
# Proposed: EEG 1D â†’ ResNet1D (or ConvNeXt1D)
```
- Tá»± nhiÃªn hÆ¡n cho time-series, khÃ´ng phá»¥ thuá»™c factorization T=HÃ—W

### 4.2 Multi-scale Mamba
Hiá»‡n táº¡i: 1 MambaBlock á»Ÿ midpoint. Thá»­:
- 2-3 MambaBlock phÃ¢n bá»‘ Ä‘á»u (early/mid/late)
- Multi-resolution: Mamba trÃªn raw + strided signal
- âš ï¸ Cáº§n benchmark: má»—i MambaBlock thÃªm ~0.04ms latency

### 4.3 Frequency-domain Branch
ThÃªm parallel branch: **STFT/Wavelet â†’ CNN** â†’ concat vá»›i time-domain embedding.
EEG biometrics literature cho tháº¥y alpha/beta band power ráº¥t discriminative.

### 4.4 Modern Backbone
Thay ResNet18/34 (2015) â†’ **ConvNeXt-Tiny** hoáº·c **EfficientNet-B0**:
- Ãt params hÆ¡n, accuracy tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c cao hÆ¡n
- CÃ³ pretrained weights tá»‘t hÆ¡n

---

## Priority Matrix

| Phase | Idea | Effort | Impact | ROI |
|---|---|---|---|---|
| 1 | â‰¥5 seeds | â¬œ Tháº¥p | ğŸ”´ Critical | â­â­â­â­â­ |
| 1 | ArcFace grid (m, s) | â¬œ Tháº¥p | P@1 +2-3% | â­â­â­â­â­ |
| 1 | Unit test P@K | â¬œ Tháº¥p | Trust | â­â­â­â­ |
| 2 | SupCon + ArcFace | ğŸŸ¡ Trung bÃ¬nh | AUROC +10-15% | â­â­â­â­ |
| 2 | Joint fine-tune | ğŸŸ¡ Trung bÃ¬nh | P@1 +3-5% | â­â­â­â­ |
| 2 | Hard-negative mining | ğŸŸ¡ Trung bÃ¬nh | AUROC +15-20% | â­â­â­â­ |
| 3 | Enhanced augmentation | ğŸŸ¡ Trung bÃ¬nh | P@1 +2-3% | â­â­â­ |
| 3 | Cross-dataset pretrain | ğŸ”´ Cao | P@1 +5-10% | â­â­â­ |
| 4 | 1D Embedder | ğŸ”´ Cao | TBD | â­â­ |
| 4 | Multi-scale Mamba | ğŸ”´ Cao | P@1 +2-5% | â­â­ |
| 4 | Frequency branch | ğŸ”´ Cao | P@1 +3-5% | â­â­ |

---

## Target Metrics (sau táº¥t cáº£ improvements)

| Metric | Hiá»‡n táº¡i (V2) | Target | Notes |
|---|---|---|---|
| **P@1** | 80-89% | **92-95%** | Phase 1+2 improvements |
| **P@5** | 78-87% | **95-98%** | Follows P@1 |
| **AUROC** | 0.42-0.56 | **0.85-0.92** | Phase 2 (SupCon + hard mining) |
| **EER** | 34-38% | **8-12%** | Phase 2 |
| **SI-SNR** | 12-37 dB | **14-40 dB** | Phase 2.2 (joint fine-tune) |
