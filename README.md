# Neuro-Biometrics üß†‚ö°Ô∏è

[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-ee4c2c.svg)](https://pytorch.org/)
[![Status](https://img.shields.io/badge/Status-Research%20Preview-blue)](https://github.com/zhugez/Neuro-Biometrics)

**Robust EEG Denoising and Biometric Verification using State Space Models (Mamba) and Metric Learning.**

> üöÄ **Latest:**
> - [2026-02-19] Refactored: extracted `experiments/shared/` module, V1/V2 are now thin wrappers (-2082 lines)
> - [2026-02-19] Fixed: deprecated AMP API, P@5 metric (CMC@5 ‚Üí true Precision@5), dead code cleanup
> - [2026-02-19] Google Drive backup via [gogcli](https://github.com/steipete/gogcli)
> - [2026-02-11] Integrated **Mamba SSM** into WaveNet denoiser (V2)

---

## üìñ Introduction

This repository implements the paper **"Enhancing EEG-based Biometrics with Mamba-augmented Denoising Autoencoders"**.

We propose a **two-stage architecture**:

| Stage | Component | Objective |
|---|---|---|
| **Stage 1** ‚Äî Denoising | WaveNet (Dilated Conv1D) + optional **Mamba Block** (SSM) | Reconstruct clean EEG signals from noisy input (SI-SNR loss) |
| **Stage 2** ‚Äî Embedding | ResNet-18/34 with metric learning head | Extract identity-robust 128-d embeddings (ArcFace / MultiSimilarity loss) |

### Why Mamba?

Standard convolutional denoisers have a fixed receptive field. **Mamba** (Selective State Space Model) provides:
- **Linear-time** sequence modeling (vs quadratic for Transformers)
- **Content-aware** gating ‚Äî selectively remembers/forgets temporal context
- **Drop-in integration** ‚Äî placed at the midpoint of the WaveNet block stack as a residual module

---

## üèóÔ∏è Architecture

```
Input EEG (B, 4, 800)                 4 EEG channels, 800 time samples
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  WaveNet Denoiser      ‚îÇ  3 blocks √ó 4 layers, dilated Conv1D
‚îÇ  ‚îú‚îÄ WaveNetBlock √ó6    ‚îÇ  dilation = 1,2,4,8 per block
‚îÇ  ‚îú‚îÄ [MambaBlock] √ó1    ‚îÇ  inserted at layer 6 (midpoint)
‚îÇ  ‚îî‚îÄ WaveNetBlock √ó6    ‚îÇ
‚îÇ  Output Conv           ‚îÇ  SI-SNR loss, 30 epochs
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ denoised (B, 4, 800)
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ResNet Embedder       ‚îÇ  Reshape 800 ‚Üí (25, 32)
‚îÇ  ‚îú‚îÄ Conv2d 3√ó3 s=1     ‚îÇ  no maxpool (preserve spatial info)
‚îÇ  ‚îú‚îÄ ResNet backbone    ‚îÇ  pretrained ImageNet features
‚îÇ  ‚îî‚îÄ FC ‚Üí ReLU ‚Üí Drop   ‚îÇ
‚îÇ       ‚Üí FC ‚Üí BN ‚Üí L2   ‚îÇ  128-d normalized embedding
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ embedding (B, 128)
         ‚ñº
  ArcFace / MultiSimilarity          30 epochs, metric learning
```

### Key Design Choices

| Decision | Rationale |
|---|---|
| **Conv1 3√ó3 stride=1** (not 7√ó7 stride=2) | EEG input is small (25√ó32) ‚Äî large kernels destroy spatial info |
| **No maxpool** | Same reason ‚Äî avoid downsampling too aggressively |
| **Deeper projection head** (FC‚ÜíReLU‚ÜíDropout‚ÜíFC‚ÜíBN) | More capacity for learning discriminative embeddings |
| **2D reshape** via `_find_2d_shape(800)` ‚Üí (25, 32) | Gives proper spatial structure for 2D convolutions |
| **Data augmentation** in Stage 2 | Gaussian noise jitter + random amplitude scaling for robustness |

---

## üõ†Ô∏è Installation

```bash
git clone https://github.com/zhugez/Neuro-Biometrics.git
cd Neuro-Biometrics
pip install -r requirements.txt
```

### Dependencies

| Package | Purpose |
|---|---|
| `torch ‚â• 2.0` | Core deep learning framework |
| `mamba-ssm` + `causal-conv1d` | Mamba SSM with CUDA kernels |
| `pytorch-metric-learning` | ArcFace, MultiSimilarity losses |
| `torchvision` | ResNet backbones |
| `mne` | EEG signal processing |

---

## üìä Usage

### 1. Download Dataset
```bash
python download_dataset.py
```

### 2. Training

```bash
# V1 Baseline: WaveNet + ResNet (no Mamba)
python experiments/v1_baseline/main.py --epochs 30 --seeds 3

# V2 Mamba: WaveNet + Mamba + ResNet
python experiments/v2_mamba/main.py --epochs 30 --seeds 2
```

### 3. Quick Tests

```bash
# Ultra-fast forward pass (1 sample, no training)
python experiments/v2_mamba/main.py --one-sample

# Synthetic smoke test (forward + dataloader)
python experiments/v2_mamba/main.py --smoke

# Tiny 1-epoch training sanity check
python experiments/v2_mamba/main.py --mini-train
```

> üí° All `--smoke`, `--one-sample`, `--mini-train` flags work for both V1 and V2.

### 4. Backup Weights

```bash
# Zip only (auto-saves to /kaggle/working/ on Kaggle)
python backup_full.py

# Zip + upload to Google Drive
python backup_full.py --gdrive --account you@gmail.com
```

<details>
<summary>üìã One-time Google Drive setup</summary>

1. Install [gogcli](https://github.com/steipete/gogcli):
   ```bash
   curl -sL https://github.com/steipete/gogcli/releases/latest/download/gogcli_0.11.0_linux_amd64.tar.gz | tar xz -C /usr/local/bin gog
   ```

2. Create a **Desktop app** OAuth client at [Google Cloud Console](https://console.cloud.google.com/auth/clients) and download `client_secret.json`

3. Authenticate:
   ```bash
   export GOG_KEYRING_PASSWORD='your_password'
   gog auth keyring file
   gog auth credentials client_secret.json
   gog auth add you@gmail.com --services drive --manual
   ```

</details>

---

## üìÅ Project Structure

```
Neuro-Biometrics/
‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îú‚îÄ‚îÄ shared/                   # Shared code (zero duplication)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py              # WaveNetDenoiser, MambaBlock, ResNetMetricEmbedder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py            # TwoStageTrainer, SISNRLoss, metrics
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ datapreprocessor.py   # Config, EEG loading, noise generation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py           # EEGPipeline, smoke/mini/one-sample, CLI
‚îÇ   ‚îú‚îÄ‚îÄ v1_baseline/              # V1: WaveNet only (thin wrapper)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py               # run_cli(use_mamba=False)
‚îÇ   ‚îî‚îÄ‚îÄ v2_mamba/                 # V2: WaveNet + Mamba (thin wrapper)
‚îÇ       ‚îú‚îÄ‚îÄ main.py               # run_cli(use_mamba=True)
‚îÇ       ‚îî‚îÄ‚îÄ README.md             # V2 detailed results
‚îú‚îÄ‚îÄ dataset/                      # EEG data (gitignored)
‚îú‚îÄ‚îÄ backup_full.py                # Zip & upload weights to Google Drive
‚îú‚îÄ‚îÄ download_dataset.py           # Download dataset from Google Drive
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

> üí° **V1 and V2 are identical** except the `use_mamba` flag. All model, trainer, data, and pipeline logic lives in `experiments/shared/`.

---

## üìà Results

> **Protocol:** Subject-disjoint ‚Äî holdout subjects {2, 5, 7, 12} never seen during training.
> Multi-seed evaluation (3 seeds), best model highlighted per noise type.

### V2: Mamba-Augmented Denoiser (30/30 epochs)

V2 adds a **MambaBlock** at the midpoint of the WaveNet denoiser + training augmentation (noise jitter, amplitude scaling).

#### Gaussian Noise

| Model | P@1 ‚Üë | P@5 ‚Üë | SI-SNR (dB) ‚Üë | AUROC ‚Üë | EER ‚Üì |
|---|---|---|---|---|---|
| ResNet34 + MultiSim | 0.814 ¬± 0.044 | 0.959 ¬± 0.010 | 12.34 ¬± 0.31 | 0.461 ¬± 0.017 | ‚Äî |
| ResNet18 + MultiSim | 0.793 ¬± 0.064 | 0.959 ¬± 0.005 | 12.34 ¬± 0.31 | 0.451 ¬± 0.009 | ‚Äî |
| **ResNet34 + ArcFace** | **0.865 ¬± 0.041** | **0.973 ¬± 0.008** | 12.34 ¬± 0.31 | 0.419 ¬± 0.013 | **34.0%** |

#### Powerline Noise (50 Hz)

| Model | P@1 ‚Üë | P@5 ‚Üë | SI-SNR (dB) ‚Üë | AUROC ‚Üë | EER ‚Üì |
|---|---|---|---|---|---|
| ResNet34 + MultiSim | 0.868 ¬± 0.028 | 0.967 ¬± 0.013 | 36.73 ¬± 1.62 | 0.464 ¬± 0.018 | ‚Äî |
| ResNet18 + MultiSim | 0.857 ¬± 0.004 | 0.969 ¬± 0.002 | 36.78 ¬± 1.85 | 0.452 ¬± 0.010 | ‚Äî |
| **ResNet34 + ArcFace** | **0.896 ¬± 0.013** | **0.977 ¬± 0.003** | 36.67 ¬± 1.44 | **0.564 ¬± 0.097** | **37.5%** |

#### EMG Noise (20‚Äì80 Hz)

| Model | P@1 ‚Üë | P@5 ‚Üë | SI-SNR (dB) ‚Üë | AUROC ‚Üë | EER ‚Üì |
|---|---|---|---|---|---|
| ResNet34 + MultiSim | 0.813 ¬± 0.003 | 0.953 ¬± 0.008 | 14.11 ¬± 0.36 | 0.454 ¬± 0.004 | ‚Äî |
| ResNet18 + MultiSim | 0.820 ¬± 0.053 | 0.962 ¬± 0.007 | 14.11 ¬± 0.37 | 0.510 ¬± 0.029 | ‚Äî |
| **ResNet34 + ArcFace** | **0.893 ¬± 0.014** | **0.976 ¬± 0.005** | 14.11 ¬± 0.37 | **0.535 ¬± 0.077** | **31.1%** |

### V1: Baseline ‚Äî WaveNet Only (20/30 epochs)

V1 uses the same WaveNet denoiser and ResNet embedder, but **without Mamba** and without training augmentation.

> ‚è≥ **V1 results pending** ‚Äî experiment ch∆∞a ch·∫°y. Ch·∫°y l·ªánh:
> ```bash
> python experiments/v1_baseline/main.py --epochs 30 --seeds 3
> ```

### V1 vs V2 Comparison

| Feature | V1 Baseline | V2 Mamba |
|---|---|---|
| **Denoiser** | WaveNet only | WaveNet + MambaBlock |
| **Stage 1 epochs** | 20 | 30 |
| **Stage 2 epochs** | 30 | 30 |
| **Training augmentation** | ‚ùå None | ‚úÖ Noise jitter + amplitude scaling |
| **Best P@1 (Gaussian)** | *pending* | **86.5%** |
| **Best P@1 (Powerline)** | *pending* | **89.6%** |
| **Best P@1 (EMG)** | *pending* | **89.3%** |

### Metric Definitions

| Metric | Description |
|---|---|
| **P@1** | Precision@1 ‚Äî fraction of queries whose nearest neighbor shares the same identity |
| **P@5** | Precision@5 ‚Äî fraction of 5 nearest neighbors that share the same identity |
| **SI-SNR** | Scale-Invariant Signal-to-Noise Ratio ‚Äî denoising quality (higher = cleaner signal) |
| **AUROC** | Area Under ROC ‚Äî binary verification performance (same vs different identity) |
| **EER** | Equal Error Rate ‚Äî threshold where FAR = FRR (lower = better, shown in detailed results) |

### Key Findings

- **ResNet34 + ArcFace** achieves best P@1 across all noise types (**86.5% / 89.6% / 89.3%**)
- ArcFace outperforms MultiSimilarity for verification (higher AUROC on powerline + EMG)
- SI-SNR is similar across models (denoiser converges independently of embedder choice)
- Latency: ResNet34 ~100¬µs, ResNet18 ~85¬µs per inference
- ‚ö†Ô∏è These are **V2 pre-fix** results. Updated metrics pending retraining with corrected embedder.

---

## üìú Citation

```bibtex
@article{zhugez2026neurobiometrics,
  title={Neuro-Biometrics: Efficient EEG Denoising via State Space Models},
  author={Ly Ngoc Vu and Huynh Cong Bang},
  year={2026}
}
```

## üõ°Ô∏è License
MIT License. For research purposes only.
